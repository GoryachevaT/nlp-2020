{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Почта для сдачи решений:  \n",
    "    bdt-mf-ml-nlp-2020-q4@bigdatateam.org\n",
    "\n",
    "**В теме письма укажите:**\n",
    "    \n",
    "    \"HW2:CompLing. ФИО\"\n",
    "\n",
    "### Пожалуйста, оцените качество заданий второго модуля [здесь](http://rebrand.ly/mfnlp2020q4_feedback_hw02)\n",
    "-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ds2o8jo0RAah"
   },
   "source": [
    "# Dependency Parsing\n",
    "\n",
    "Мы будем использовать **POS tagging** и **dependency parsing** из популярного пакета [SpaCy](https://spacy.io)\n",
    "\n",
    "В SpaCy используется подход Universal Dependencies\n",
    "\n",
    "## Установим модель SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_H8a1Oh9hVxr"
   },
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В SpaCy есть возможность не только размечать части речи и синтаксическиезависимости, но и красиво визуализировать, используя ``displacy``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "En8gggO1ToI_",
    "outputId": "fe7c2ed2-033a-40de-cc53-dbc7c667ce55"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a09d37d977e04daa855c1ab9e80b7d5b-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">test.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a09d37d977e04daa855c1ab9e80b7d5b-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a09d37d977e04daa855c1ab9e80b7d5b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a09d37d977e04daa855c1ab9e80b7d5b-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a09d37d977e04daa855c1ab9e80b7d5b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a09d37d977e04daa855c1ab9e80b7d5b-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a09d37d977e04daa855c1ab9e80b7d5b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en')\n",
    "test_doc = nlp('This is a test.')\n",
    "displacy.render(test_doc, jupyter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy сама токенизирует текст, все токены становятся специальными элементами, в которых хранятся сам токен,а также его таги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_bc9NNT1UL_5",
    "outputId": "b5c8496c-c36a-4d79-8b61-90f195aa3300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(This, 'DET'), (is, 'AUX'), (a, 'DET'), (test, 'NOUN'), (., 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "print([(token, token.pos_) for token in test_doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test.\n"
     ]
    }
   ],
   "source": [
    "print(test_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hAWRioM1VPYJ"
   },
   "source": [
    "### Для задания мы используем известный корпус литературных произведений - Project Gutenberg. \n",
    "Из корпуса мы возьмем довольно длинный роман Джейн Остин \"Чувство и чувствительность\" (Sense and Sensibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iMAyOna7Ovjj",
    "outputId": "9b6ee0b3-7f5f-44eb-86a1-65a2e75ee3dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/antonina.goryacheva/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg\n",
    "sentences = gutenberg.sents('austen-sense.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопросы\n",
    "\n",
    "**1. Сколько предложений в этом романе? Сколько уникальных токенов?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4999"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# предложений\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6398"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# уникальных тоокенов\n",
    "len(set([word.lower() for text in sentences for word in text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Найдите 5 наиболее частотных глагольных словоформ? Найдите 5 наиболее частотных лемм (начальных форм) глаголов? (глагол-verb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Their estate was large , and their residence was at Norland Park , in the centre of their property , where , for many generations , they had lived in so respectable a manner as to engage the general good opinion of their surrounding acquaintance .'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(sentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = nlp(' '.join(sentences[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# глагольные словоформы - это?\n",
    "# сделать лемматизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Their, 'DET'),\n",
       " (estate, 'NOUN'),\n",
       " (was, 'AUX'),\n",
       " (large, 'ADJ'),\n",
       " (,, 'PUNCT'),\n",
       " (and, 'CCONJ'),\n",
       " (their, 'DET'),\n",
       " (residence, 'NOUN'),\n",
       " (was, 'AUX'),\n",
       " (at, 'ADP'),\n",
       " (Norland, 'PROPN'),\n",
       " (Park, 'PROPN'),\n",
       " (,, 'PUNCT'),\n",
       " (in, 'ADP'),\n",
       " (the, 'DET'),\n",
       " (centre, 'NOUN'),\n",
       " (of, 'ADP'),\n",
       " (their, 'DET'),\n",
       " (property, 'NOUN'),\n",
       " (,, 'PUNCT'),\n",
       " (where, 'ADV'),\n",
       " (,, 'PUNCT'),\n",
       " (for, 'ADP'),\n",
       " (many, 'ADJ'),\n",
       " (generations, 'NOUN'),\n",
       " (,, 'PUNCT'),\n",
       " (they, 'PRON'),\n",
       " (had, 'AUX'),\n",
       " (lived, 'VERB'),\n",
       " (in, 'ADP'),\n",
       " (so, 'ADV'),\n",
       " (respectable, 'ADJ'),\n",
       " (a, 'DET'),\n",
       " (manner, 'NOUN'),\n",
       " (as, 'SCONJ'),\n",
       " (to, 'PART'),\n",
       " (engage, 'VERB'),\n",
       " (the, 'DET'),\n",
       " (general, 'ADJ'),\n",
       " (good, 'ADJ'),\n",
       " (opinion, 'NOUN'),\n",
       " (of, 'ADP'),\n",
       " (their, 'DET'),\n",
       " (surrounding, 'VERB'),\n",
       " (acquaintance, 'NOUN'),\n",
       " (., 'PUNCT')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token, token.pos_) for token in test_doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ujsWoL1NZ5nG"
   },
   "source": [
    "## Грамматика зависимостей (Dependency parsing) and PP attachment\n",
    "\n",
    "Теперь посмотрим как глаголы и предложные фразы (prepositional phrase или PP) могут быть связаны в предложении.\n",
    "- Вершина *предложной фразы* - предлог. Например, \"**in** the house\", \"**on** the table\", \"**with** my friend\"\n",
    "\n",
    "\n",
    "### Вопросы\n",
    "\n",
    "  3. В чем отличие в зависимости предложных фраз между предложениями группы (A) и предложениями группы (B)? \n",
    "  Посмотрите на схему зависимостей, которую можно сделать с помощью SpaCy.\n",
    "  - Подсказка: какие \"родительские\" вершины у предложных групп?\n",
    "  \n",
    "(A)\n",
    "  * I eat an apple in my room.\n",
    "  * We listen to music at the theater.\n",
    "  * John visited Brazil with his friend.\n",
    "  \n",
    "(B)\n",
    "  * I see a fly in my soup.\n",
    "  * She knows the man at the store.\n",
    "  * I photographed a man with a bowtie.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бывают случаи, когда не очевидно, к какому элементу предложения нужно присоединить предложную фразу\n",
    "- Вспомните пример из лекции \"I shot an elephant in my pyjamas\"\n",
    "\n",
    "На примере нашего корпуса попробуем понять, какую \"родительскую\" вершину для предложных фраз предпочитает SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7cqzisHbfIZG"
   },
   "source": [
    "\n",
    "**### Вопросы:**\n",
    "\n",
    "  4. Выберите все случаи, когда предложная фраза присоединяется к глаголу (verb), как в группе предложений (A) выше.\n",
    "      - Создайте список для всех пар (tupples) вида (лемматизированный глагол, лемматизированный предлог) = (verb lemma, preposition lemma).\n",
    "      - Посчитайте сколько таких случаев.\n",
    "      - Выпишите 5 наиболее частотный пар (verb lemma, preposition lemma)\n",
    "      - Подсказка: В spaCy можно получить зависимый токен  с помощью *token*.children, а тип зависимости с помощью *child.dep_*. \n",
    "  \n",
    "  5. Сделайте тоже самое для случаев, когда предложная фраза присоединяется к дополнению глагола (verb's object), как в группе предложений (B). \n",
    "      - Создайте список для всех пар (tupples) вида (лемматизированный дополнение, лемматизированный предлог) = (verb's object lemma, preposition lemma).\n",
    "      - Посчитайте сколько таких случаев.\n",
    "      - Выпишите 5 наиболее частотный пар (verb's object, preposition lemma)?\n",
    "  ?\n",
    "  6. Постройте систему зависимостей для предложения \"I shot an elephant in my pyjamas\"\n",
    "      - К чему присоединена предложная группа?\n",
    "      - Кто был в пижаме с точки зрения SpaCy?\n",
    "\n",
    "**Бонус:** Выберите несколько случайных предложений из корпуса. Постройте для них систему зависимостей. \n",
    "- Похоже на правду?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение присылйте на почту  bdt-mf-ml-nlp-2020-q4@bigdatateam.org  \n",
    "\n",
    "В теме письма укажите: ``HW2:CompLing. ФИО``\n",
    "\n",
    "Пожалуйста, оставьте обратную связь о задании [по ссылке](http://rebrand.ly/mfnlp2020q4_feedback_hw02). Она (при желании) анонимна ;)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP Core 2 - Exercise 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
